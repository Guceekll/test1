# session_utils.py
import re
import difflib
import unicodedata
from typing import List

# ---------- 通用清洗 ----------
def normalize_text(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s)   # 全角半角统一（适合日文标点/数字/空格）
    s = s.strip().lower()
    s = re.sub(r"\s+", " ", s)             # 多余空格合并
    return s

# ---------- 1) 用户可能想结束（多语言 + 分级触发） ----------
# 强信号：几乎可以直接认为是“结束”
END_STRONG_PATTERNS = [
    # 中文
    r"(就这样|先这样|差不多了|不用了|可以了|结束|到这|没了|没有了|不需要继续|先到这|这次先这样)",
    # 英文
    r"\b(that'?s all|that is all|done|finish|finished|we can stop|stop here|end here)\b",
    # 日文
    r"(以上です|終わりにします|ここまで(です)?|今日はこの辺で|このへんで|おわり|もう大丈夫です|もういいです)"
]

# 弱信号：更口语化/模糊，需配合“句子整体很短”一起判定，减少误报
END_WEAK_PATTERNS = [
    # 中文
    r"(差不多|先这样吧|这样吧|先到这吧)",
    # 英文
    r"\b(ok|okay|all good|good|that'?s it)\b",
    r"\b(i'?m good|i am good|i'?m done|i am done)\b",
    # 日文（更口语）
    r"(そんなところ(です)?|こんな感じ(です)?|大丈夫です|以上でお願いします)"
]

END_STRONG_RE = re.compile("|".join(END_STRONG_PATTERNS), re.IGNORECASE)
END_WEAK_RE   = re.compile("|".join(END_WEAK_PATTERNS),   re.IGNORECASE)

def user_might_want_to_end(message: str) -> bool:
    """
    规则：
    1) 命中强信号 -> 直接 True
    2) 命中弱信号 -> 仅当消息整体较短（<= 16 字符，NFKC 后计数）时 True，避免误伤
    """
    if not message:
        return False
    raw = message
    msg = normalize_text(message)

    if END_STRONG_RE.search(raw) or END_STRONG_RE.search(msg):
        return True

    if END_WEAK_RE.search(raw) or END_WEAK_RE.search(msg):
        # 长句里出现弱信号多半不是“结束”，加长度保护
        return len(unicodedata.normalize("NFKC", raw)) <= 16

    return False

# ---------- 2) 连续“空/无信息”输入（多语言口癖 + 表情/标点） ----------
_ONLY_DOTS_OR_PUNCS = re.compile(r"^[\.\·…、。\！!？?\-—~～\s]+$")
_NO_ALNUM_CJK       = re.compile(r"^[^\w\u4e00-\u9fff\u3040-\u30ff\u3400-\u4dbf\uac00-\ud7af]+$")

LOW_INFO_TOKENS = {
    # 中文/中式口癖
    "嗯","嗯嗯","额","呃","哦","啊","好","ok","ok~","行","可以",
    # 英文口癖
    "ok","okay","k","hmm","uh","uhh","um","yeah","yup","mm",
    # 日文口癖
    "うん","ええ","はい","うーん","えー","まぁ","大丈夫","了解","りょうかい","おけ","オケ","okです",
}

def _is_blankish(s: str) -> bool:
    if not s:
        return True
    raw = s.strip()
    if raw == "":
        return True
    # 纯省略号/纯标点/全是空白
    if _ONLY_DOTS_OR_PUNCS.match(raw):
        return True
    # 没有任何字母/数字/中日文 CJK 字符（基本就是符号/emoji）
    if _NO_ALNUM_CJK.match(raw):
        return True
    # 极短且是低信息口癖（多语言）
    if len(unicodedata.normalize("NFKC", raw)) <= 4 and normalize_text(raw) in LOW_INFO_TOKENS:
        return True
    return False

def user_gave_blank_responses(last_inputs: List[str], need_consecutive: int = 3) -> bool:
    if not last_inputs or len(last_inputs) < need_consecutive:
        return False
    window = last_inputs[-need_consecutive:]
    return all(_is_blankish(x) for x in window)

# ---------- 3) 答案重复（语言无关，归一化 + 相似度） ----------
def has_repeated_answers(answer_log: List[str],
                         min_samples: int = 3,
                         recent_k: int = 3,
                         sim_threshold: float = 0.85) -> bool:
    """
    - 至少 min_samples 条才判定
    - 取最近 1 条与之前 recent_k 条做相似度
    - 使用 difflib.SequenceMatcher（对多语言适用）
    """
    if len(answer_log) < min_samples:
        return False
    cleaned = [normalize_text(a) for a in answer_log if a is not None]
    last = cleaned[-1]
    prevs = cleaned[-(recent_k+1):-1]
    for p in prevs:
        ratio = difflib.SequenceMatcher(a=last, b=p).ratio()
        if ratio >= sim_threshold:
            return True
    return False
